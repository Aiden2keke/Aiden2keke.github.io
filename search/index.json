[{"content":" Introduction The single inverted pendulum (SIP) model describes an unstable dynamic system where a vertical rod (pendulum) is mounted on a cart that can freely move along a horizontal surface. The wheels of the cart are driven by a motor, and by controlling the motor, the cart\u0026rsquo;s motion can be adjusted to balance the rod.\nIn this system:\nInput: Torque applied to the cart\u0026rsquo;s wheels. Output: Position of the cart and the angle of the rod relative to the vertical. Notations Notation Definition M Mass of cart m Mass of pendulum L Distance from the center of gravity of pendulum to the joint I The moment of inertia of pendulum b Damping coefficient u(t) External force x Displacement of cart Î¸ Angle of pendulum with respect to -y direction Force Analysis From Figure 2, we can derive the following equations:\n$$ M\\ddot{x} + b\\dot{x} + N = F \\tag{1} $$\nFrom Figure 3, we can derive:\n$$ N = m \\frac{d^2}{dt^2}(x + l\\sin\\theta) = m\\ddot{x} + ml\\ddot{\\theta}\\cos\\theta - ml\\dot{\\theta}^2\\sin\\theta \\tag{2} $$$$ P = mg + m \\frac{d^2}{dt^2}(l\\cos\\theta) = mg - ml\\ddot{\\theta}\\sin\\theta - ml\\dot{\\theta}^2\\cos\\theta \\tag{3} $$$$ I\\ddot{\\theta} = -P l\\sin\\theta - N l\\cos\\theta \\tag{4} $$ ODE Substituting equation (2) into equation (1), and substituting equations (2), (3) into equation (4) yields:\n$$ (M+m)\\ddot{x} + b\\dot{x} + ml\\ddot{\\phi}\\cos\\theta - ml\\dot{\\theta}^2\\sin\\theta = F \\tag{5} $$$$ (I - ml^2\\sin^2\\theta + ml^2\\cos^2\\theta)\\ddot{\\theta} - 2ml^2\\sin\\theta\\cos\\theta\\dot{\\theta}^2 + lm g\\sin\\theta = -lm\\cos\\theta\\ddot{x} \\tag{6} $$$$\\theta = \\pi + \\phi $$$$\\phi \\to 0 , \\sin\\theta \\approx -\\phi , \\cos\\theta \\approx -1 , \\dot{\\theta}^2 \\approx 0 $$, we get:\n$$ (M+m)\\ddot{x} + b\\dot{x} + ml\\ddot{\\phi} = F \\tag{7} $$$$ (I + ml^2)\\ddot{\\phi} - mgl\\phi = ml\\ddot{x} \\tag{8} $$ Transfer Function After applying Laplace transform, we get:\n$$ \\big((M+m)s^2 + bs\\big)X(s) + mls^2\\Phi(s) = U(s) \\tag{9} $$$$ \\big((I + ml^2)s^2 - mgl\\big)\\Phi(s) = mls^2 X(s) \\tag{10} $$where \\( F = u(t) \\). Therefore, the transfer functions are:\n$$ G_x(s) = \\frac{X(s)}{U(s)} = \\frac{(I + ml^2)s^2 - mgl}{\\big((M+m)(I+ml^2) - m^2l^2\\big)s^4 + b(I+ml^2)s^3 - mgl(M+m)s^2 - bmgls} $$$$ G_\\phi(s) = \\frac{\\Phi(s)}{U(s)} = \\frac{mls}{\\big((M+m)(I+ml^2) - m^2l^2\\big)s^3 + b(I+ml^2)s^2 - mgl(M+m)s - bmgl} $$ Matrix Form $$ \\vec{x} = \\begin{bmatrix} x \\\\ \\dot{x} \\\\ \\phi \\\\ \\dot{\\phi} \\end{bmatrix}, \\quad \\dot{\\vec{x}} = A\\vec{x} + B\\vec{u}, \\quad \\vec{y} = C\\vec{x} + D\\vec{u} $$$$ p = I(M+m) + Mml^2 $$, the matrices are defined as:\n$$ A = \\begin{bmatrix} 0 \u0026 1 \u0026 0 \u0026 0 \\\\\\ 0 \u0026 -\\frac{(I+ml^2)b}{p} \u0026 \\frac{(m^2g l^2)}{p} \u0026 0 \\\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\\\ 0 \u0026 -\\frac{mlb}{p} \u0026 \\frac{mgl(M+m)}{p} \u0026 0 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0 \\\\\\ \\frac{(I+ml^2)}{p} \\\\\\ 0 \\\\\\ \\frac{ml}{p} \\end{bmatrix} $$$$ C = \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 0 \\\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix}, \\quad D = \\begin{bmatrix} 0 \\\\\\ 0 \\end{bmatrix} $$The above matrices can be defined and calculated in Python as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import numpy as np # System parameters p = (m + M) * (I + m * L**2) - (m * L)**2 # State-space matrices A = np.array([[0, 1, 0, 0], [0, -(I + m * L**2) * b / p, (m * L)**2 * g / p, 0], [0, 0, 0, 1], [0, -m * L * b / p, m * g * L * (M + m) / p, 0]]) B = np.array([[0], [(I + m * L**2) / p], [0], [m * L / p]]) C = np.array([[1, 0, 0, 0], [0, 0, 1, 0]]) D = np.array([[0], [0]]) LQR Control The performance index for the LQR control is given by:\n$$ J_{\\text{min}} = \\int_{0}^{\\infty} \\big(x^T Q x + u^T R u\\big) dt $$The control law is defined as:\n$$ u = -Kx = -[k_1, k_2, \\dots] \\begin{bmatrix} x_1 \\\\\\ x_2 \\\\\\ \\vdots \\end{bmatrix} $$The closed-loop state-space equation becomes:\n$$ \\dot{\\vec{x}} = (A - BK)\\vec{x} = A_{\\text{cl}} \\vec{x} $$For this system, the \\( Q \\) matrix is defined as:\n$$ Q = \\begin{bmatrix} a \u0026 0 \u0026 0 \u0026 0 \\\\\\ 0 \u0026 b \u0026 0 \u0026 0 \\\\\\ 0 \u0026 0 \u0026 c \u0026 0 \\\\\\ 0 \u0026 0 \u0026 0 \u0026 d \\end{bmatrix} $$Where:\nIncreasing \\( a \\) increases the weight on the cart\u0026rsquo;s position, leading to faster balance. Increasing \\( c \\) increases the weight on the pendulum\u0026rsquo;s angle, allowing recovery from larger offset angles. Increasing \\( R \\) slows down the balancing process. Python Code:\nThe LQR control can be implemented in Python as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Manually define the Q matrix and set the weights Q = np.zeros((4, 4)) Q[0, 0] = 1 # Car position weight Q[2, 2] = 100 # Swing Angle weight R = 1 # Calculate the LQR feedback gain K K, _, _ = ctrl.lqr(A, B, Q, R) # Construct a closed-loop state-space system Ac = A - B @ K Bc = B Cc = C Dc = D # Create a closed-loop system sys_cl = ctrl.ss(Ac, Bc, Cc, Dc) Simulation Python Code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # Simulation parameters M = 0.5 # kg m = 0.2 # kg b = 0.1 # N/m/s g = 9.8 # m/s^2 L = 0.3 # m I = 0.018 # kg*m^2 t = np.arange(0, 10.01, 0.01) # Time array r = 0.2 * np.ones_like(t) # Reference input # Feedforward gain Nbar calculation Cn = np.array([[1, 0, 0, 0]]) sys_ss = ctrl.ss(A, B, Cn, 0) Nbar = 1.0 / (Cn @ np.linalg.inv(A - B @ K) @ B) # Simulate closed-loop system response t, y = ctrl.forced_response(sys_cl, T=t, U=Nbar * r) # Plot the response fig, ax1 = plt.subplots() ax2 = ax1.twinx() ax1.plot(t, y[0], \u0026#39;g-\u0026#39;, label=\u0026#39;Cart Position (m)\u0026#39;) ax2.plot(t, y[1], \u0026#39;b-\u0026#39;, label=\u0026#39;Pendulum Angle (radians)\u0026#39;) ax1.set_xlabel(\u0026#39;Time (s)\u0026#39;) ax1.set_ylabel(\u0026#39;Cart Position (m)\u0026#39;, color=\u0026#39;g\u0026#39;) ax2.set_ylabel(\u0026#39;Pendulum Angle (radians)\u0026#39;, color=\u0026#39;b\u0026#39;) plt.title(\u0026#39;Step Response with LQR Control\u0026#39;) plt.show() We can see the simulation result in Figure 4.\nMujoco Simulation The Mujoco simulation demonstrates the performance of the LQR control applied to the inverted pendulum system. Below is the Python code to simulate the system in the Mujoco environment:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Initialize the MuJoCo environment env = gym.make(\u0026#34;InvertedPendulum-v5\u0026#34;, render_mode=\u0026#34;human\u0026#34;) observation, info = env.reset(seed=42) # Simulation loop for _ in range(1000): # Get current status cart_pos, cart_vel, pole_angle, pole_angular_vel = observation state = np.array([cart_pos, cart_vel, pole_angle, pole_angular_vel]) # Computational control input u = -K @ state u = np.clip(u, env.action_space.low, env.action_space.high) # Perform the action and get the new state observation, reward, done, truncated, info = env.step([u[0]]) # If terminated, reset the environment if done or truncated: observation, info = env.reset() env.close() We can see the simulation result in Figure 5.\nReference https://zhuanlan.zhihu.com/p/54071212?utm_psn=1853238306768289792\n","date":"2024-12-20T18:22:50-06:00","permalink":"http://localhost:1313/p/control_the_first_order_inverted_pendulum_with_lqr_in_mujoco_simulation/","title":"Control_the_first_order_inverted_pendulum_with_LQR_in_Mujoco_simulation"},{"content":"Hi! Welcome to my Academic Website I am a junior student majoring in Mechanical Engineering at Zhejiang University and the University of Illinois at Urbana-Champaign.\nIf you are interested, please feel free to reach out via email:\nyidong.22@intl.zju.edu.cn yidongz4@illinois.edu Education University of Illinois at Urbana-Champaign\nMechanical Engineering (double-degree)\nSep. 2022 - May. 2026\nZhejiang University\nMechanical Engineering (double-degree)\nSep. 2022 - May. 2026\nResearch Interests Advanced Control Learning-Based Quadruped Robotics Adaptation Deep Reinforcement Learning Research Experience Take a Look at Research\nProjects Take a Look at Project\nSkills Tools: Git, Python, LaTeX, MATLAB, CAD modeling Advanced Control: Beginner Reinforcement Learning: Beginner Prizes \u0026amp; Awards Second Prize, Zhejiang University Scholarship (Oct. 2024) Zhejiang Provincial Government Scholarship (Oct. 2024) Annual Excellent League Leader (June 2024) Second Prize, Zhejiang University Scholarship (Oct. 2023) Annual Excellent League Leader (June 2023) Third Prize, Concrete Canoe Design Competition of Zhejiang University (June 2023) Second Prize, Undergraduate Structural Design Competition of Zhejiang University (May 2023) ","date":"2024-12-20T18:21:41-06:00","permalink":"http://localhost:1313/p/self_introduction/","title":"Self_introduction"}]